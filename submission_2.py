# -*- coding: utf-8 -*-
"""Submission 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPu-PHwIOAj00l_iZRmWuDLbnHanRMXM
"""

import tensorflow as tf

# Commented out IPython magic to ensure Python compatibility.
import zipfile
import os
import glob 
import warnings


from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

from keras.preprocessing import image
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

from google.colab import files
files.upload()

!pip install -q kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d chetankv/dogs-cats-images

import logging
logging.getLogger('tensorflow').disabled = True

# melakukan ekstraksi pada file zip
import zipfile,os
local_zip = '/content/dogs-cats-images.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

dir_dataset = "/content/dataset/training_set"

os.listdir(dir_dataset)

!rm -rf /content/dataset/.ipynb_checkpoints

dir_dogs = os.path.join("/content/dataset/training_set/dogs")
dir_cats = os.path.join("/content/dataset/training_set/cats")

print('total gambar kucing :', len(os.listdir(dir_cats)))
print('total gambar anjing :', len(os.listdir(dir_dogs)))

# Commented out IPython magic to ensure Python compatibility.
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
imgCats = image.load_img('/content/dataset/training_set/cats/cat.1.jpg')
imgplot = plt.imshow(imgCats)

imgDogs = image.load_img('/content/dataset/training_set/dogs/dog.1.jpg')
imgplot = plt.imshow(imgDogs)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
 
 
train_dir = os.path.join('/content/dataset/training_set')
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    shear_range=0.2,
#   fill_mode = 'nearest',
    horizontal_flip=True,
    validation_split=0.2) # set validation split

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=True,
    subset='training') # set as training data

validation_generator = train_datagen.flow_from_directory(
    train_dir,# same directory as training data
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=False,
    subset='validation')

import tensorflow as tf
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.optimizers.Adam(),
              loss='binary_crossentropy',
              metrics = ['accuracy'])

model.summary()

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.8 and logs.get('val_accuracy')> 0.8):
      print("\nAkurasi telah mencapai >80%!")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(
      train_generator,
      steps_per_epoch=30,
      epochs=85,
      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi
      verbose=2,
      callbacks=[callbacks])

# Mengambil Nilai Accuracy 
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
# Mengambil Nilai Loss 
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

# Plot Accruracy
plt.plot(epochs, acc, 'r', label='Train accuracy')
plt.plot(epochs, val_acc, 'g', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

# Plot Loss
plt.plot(epochs, loss, 'r', label='Train loss')
plt.plot(epochs, val_loss, 'g', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)
plt.figure()
plt.show()

!pip install tensorflowjs

# Menghilangkan Warning
warnings.filterwarnings('ignore')

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

